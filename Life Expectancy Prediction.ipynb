{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "waiting-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collect-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from nose.tools import *\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from scipy import stats\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lined-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 List of countries by GDP (nominal)\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
    "t_gdp = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "horizontal-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_gdp[1].iloc[190:199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elder-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with null fields\n",
    "t_gdp[1] = t_gdp[1].dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elementary-calculator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first 3 rows, keep rows 3 to 195, remove irrelevant row (index 5)\n",
    "t_gdp[1] = t_gdp[1].iloc[3:195, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "friendly-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_gdp[1].drop([5], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seventh-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first column, keep second & third column\n",
    "t_gdp[1] = t_gdp[1].iloc[ :, [1,2] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "possible-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\core\\frame.py:4438: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "# replace column index with column names\n",
    "t_gdp[1].rename(columns={1: 'Country', 2: 'GDP(US$mil)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hybrid-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use below to clean up data points\n",
    "# df = t_gdp[1][ t_gdp[1]['Country'].str.contains(\"]\") ]\n",
    "# df\n",
    "t_gdp[1].Country.replace(['China[n 2]'], ['China'], inplace=True)\n",
    "t_gdp[1].Country.replace(['Russia[n 3]'], ['Russia'], inplace=True)\n",
    "t_gdp[1].Country.replace(['Syria[n 4]'], ['Syria'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "conservative-person",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP(US$mil)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country, GDP(US$mil)]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_gdp[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "going-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_gdp[1].to_csv('t_gdp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "falling-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2 List of countries by Dengue fever outbreaks\n",
    "url = 'https://en.wikipedia.org/wiki/Dengue_fever_outbreaks'\n",
    "t_dengue = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "minute-mixture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Confirmed Cases(Year: 2010)</th>\n",
       "      <th>Suspected Cases(Year: 2010)</th>\n",
       "      <th>Reported Deaths(Year: 2010)</th>\n",
       "      <th>Compared with previous year</th>\n",
       "      <th>Figures as of**</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World (sum of all regions)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1785059</td>\n",
       "      <td>N.A.</td>\n",
       "      <td>2398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>–</td>\n",
       "      <td>1011548</td>\n",
       "      <td>–</td>\n",
       "      <td>656</td>\n",
       "      <td>406269</td>\n",
       "      <td>mid Oct[31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>–</td>\n",
       "      <td>121600</td>\n",
       "      <td>–</td>\n",
       "      <td>161</td>\n",
       "      <td>–</td>\n",
       "      <td>Sep 24[32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155,000 and 1386 deaths[33]</td>\n",
       "      <td>no date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippines</td>\n",
       "      <td>–</td>\n",
       "      <td>119789</td>\n",
       "      <td>–</td>\n",
       "      <td>724</td>\n",
       "      <td>49,319 (up 140%)</td>\n",
       "      <td>Nov 17[34]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Country Region Confirmed Cases(Year: 2010)  \\\n",
       "0  World (sum of all regions)    NaN                     1785059   \n",
       "1                      Brazil      –                     1011548   \n",
       "2                    Colombia      –                      121600   \n",
       "3                   Indonesia      –                           –   \n",
       "4                 Philippines      –                      119789   \n",
       "\n",
       "  Suspected Cases(Year: 2010) Reported Deaths(Year: 2010)  \\\n",
       "0                        N.A.                        2398   \n",
       "1                           –                         656   \n",
       "2                           –                         161   \n",
       "3                         NaN                         NaN   \n",
       "4                           –                         724   \n",
       "\n",
       "   Compared with previous year Figures as of**  \n",
       "0                          NaN             NaN  \n",
       "1                       406269     mid Oct[31]  \n",
       "2                            –      Sep 24[32]  \n",
       "3  155,000 and 1386 deaths[33]         no date  \n",
       "4             49,319 (up 140%)      Nov 17[34]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dengue[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "coordinated-coordination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['World (sum of all regions)', 'Brazil', 'Colombia', 'Indonesia',\n",
       "       'Philippines', 'Venezuela', 'Thailand', 'Vietnam', 'Honduras',\n",
       "       'Malaysia', 'Sri Lanka', 'Costa Rica', 'Laos', 'Puerto Rico',\n",
       "       'Paraguay', 'Mexico', 'Dominican Republic', 'El Salvador', 'India',\n",
       "       'Pakistan', 'Singapore', 'Cambodia', 'Saudi Arabia', 'France',\n",
       "       'Guatemala', 'Taiwan', 'Trinidad and Tobago', 'Nepal',\n",
       "       'United States', 'Australia'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_dengue[0].Country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "responsible-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   Country                      37 non-null     object\n",
      " 1   Region                       36 non-null     object\n",
      " 2   Confirmed Cases(Year: 2010)  37 non-null     object\n",
      " 3   Suspected Cases(Year: 2010)  35 non-null     object\n",
      " 4   Reported Deaths(Year: 2010)  31 non-null     object\n",
      " 5   Compared with previous year  24 non-null     object\n",
      " 6   Figures as of**              36 non-null     object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "t_dengue[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "knowing-listening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Dengue_Cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>1011548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippines</td>\n",
       "      <td>119789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>124931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>108863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country Dengue_Cases\n",
       "1       Brazil      1011548\n",
       "2     Colombia       121600\n",
       "4  Philippines       119789\n",
       "5    Venezuela       124931\n",
       "6     Thailand       108863"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep first column, keep third column\n",
    "t_dengue[0] = t_dengue[0].iloc[ :, [0,2] ]\n",
    "\n",
    "# remove irrelevant row 0, row 3\n",
    "t_dengue[0].drop([0,3], axis=0, inplace=True)\n",
    "\n",
    "# replace column index with column names\n",
    "t_dengue[0].rename(columns={'Confirmed Cases(Year: 2010)': 'Dengue_Cases'}, inplace=True)\n",
    "\n",
    "# edit cell value\n",
    "t_dengue[0].loc[34, 'Dengue_Cases'] = 198\n",
    "\n",
    "# remove non-digit characters\n",
    "t_dengue[0]['Dengue_Cases'].replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "\n",
    "t_dengue[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "absolute-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dengue[0].to_csv('t_dengue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "specific-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3 List of countries by population\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_population_in_2010'\n",
    "t_pop = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alone-sitting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country / territory</th>\n",
       "      <th>Population2010(OECD estimate)</th>\n",
       "      <th>Changefrom 2005*</th>\n",
       "      <th>Area (km2)[1]</th>\n",
       "      <th>Populationdensity(peopleper km2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>—</td>\n",
       "      <td>World</td>\n",
       "      <td>6843522711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>1339724852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9596961.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>India</td>\n",
       "      <td>1182105564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3287263.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>United States</td>\n",
       "      <td>309349689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9833520.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>237641326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904569.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank Country / territory  Population2010(OECD estimate)  Changefrom 2005*  \\\n",
       "0    —               World                     6843522711               NaN   \n",
       "1    1               China                     1339724852               NaN   \n",
       "2    2               India                     1182105564               NaN   \n",
       "3    3       United States                      309349689               NaN   \n",
       "4    4           Indonesia                      237641326               NaN   \n",
       "\n",
       "   Area (km2)[1]  Populationdensity(peopleper km2)  \n",
       "0            NaN                               NaN  \n",
       "1      9596961.0                             140.0  \n",
       "2      3287263.0                             360.0  \n",
       "3      9833520.0                              31.0  \n",
       "4      1904569.0                             125.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_pop[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "prescribed-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep second/third/fifth/sixth column\n",
    "# t_pop[1] = t_pop[1].iloc[ :, [1,2,4,5] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bridal-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove irrelevant row 0, 199\n",
    "# t_pop[1].drop([0, 199], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dietary-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column names\n",
    "t_pop[1].columns = ['Country', 'Population', 'Area(km²)', 'Pop_density']\n",
    "\n",
    "# remove rows with null field\n",
    "t_pop[1].dropna(how = 'any', inplace=True)     \n",
    "\n",
    "# change column type and calculate Pop_density\n",
    "t_pop[1]['Population'] = t_pop[1]['Population'].astype(int)\n",
    "t_pop[1]['Area(km²)'] = t_pop[1]['Area(km²)'].astype(float).astype(int)\n",
    "t_pop[1]['Pop_density'] = t_pop[1]['Pop_density'].astype(float)\n",
    "t_pop[1]['Pop_density'] = (t_pop[1]['Population'] / t_pop[1]['Area(km²)']).round(1)\n",
    "\n",
    "# use below to clean up data points\n",
    "# df = t_pop[1][ t_pop[1]['Country'].str.contains(\"]\") ]\n",
    "# df\n",
    "t_pop[1].Country.replace(['India[2]'], ['India'], inplace=True)\n",
    "t_pop[1].Country.replace(['Australia[3]'], ['Australia'], inplace=True)\n",
    "t_pop[1].Country.replace(['Finland[4]'], ['Finland'], inplace=True)\n",
    "t_pop[1].Country.replace(['Norway[5]'], ['Norway'], inplace=True)\n",
    "t_pop[1].Country.replace(['Mauritius[6]'], ['Mauritius'], inplace=True)\n",
    "\n",
    "t_pop[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "psychological-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pop[1].to_csv('t_pop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "stable-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4 List of countries by birth rate\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_sovereign_states_and_dependent_territories_by_birth_rate'\n",
    "t_birth = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bridal-mexican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a&gt;span,.mw-parser-output .navbar a&gt;abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by population statistics</th>\n",
       "      <th>.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a&gt;span,.mw-parser-output .navbar a&gt;abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by population statistics.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global</td>\n",
       "      <td>Current population Demographics of the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Continents/subregions</td>\n",
       "      <td>Africa Antarctica Asia Europe North America Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intercontinental</td>\n",
       "      <td>Americas Arab world Commonwealth of Nations Eu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cities/urban areas</td>\n",
       "      <td>World cities National capitals Megacities Mega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Past and future</td>\n",
       "      <td>Past and future population World population es...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by population statistics  \\\n",
       "0                                             Global                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1                              Continents/subregions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "2                                   Intercontinental                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "3                                 Cities/urban areas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "4                                    Past and future                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "  .mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by population statistics.1  \n",
       "0       Current population Demographics of the world                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "1  Africa Antarctica Asia Europe North America Ca...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "2  Americas Arab world Commonwealth of Nations Eu...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "3  World cities National capitals Megacities Mega...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "4  Past and future population World population es...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_birth[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "productive-upper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep first & forth column\n",
    "t_birth[1] = t_birth[1].iloc[ :, [0,3] ]\n",
    "\n",
    "# remove irrelevant row 0\n",
    "t_birth[1].drop([0], axis=0, inplace=True)\n",
    "\n",
    "# remove rows with null field\n",
    "t_birth[1].dropna(how = 'any', inplace=True) \n",
    "\n",
    "# rename column names\n",
    "t_birth[1].columns = ['Country', 'Birth Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "swedish-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_birth[1].to_csv('t_birth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vanilla-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 List of countries by Environmental Performance Index\n",
    "url = 'https://epi.envirocenter.yale.edu/epi-topline'\n",
    "t_env = pd.read_html(url)\n",
    "t_env[0].head()\n",
    "# keep first & third column\n",
    "t_env[0] = t_env[0].iloc[ :, [0,2] ]\n",
    "\n",
    "# rename column names\n",
    "t_env[0].columns = ['Country', 'EPI']\n",
    "t_env[0].to_csv('t_env.csv')\n",
    " \n",
    "# # Table 6 Global cancer data by country\n",
    "# url = 'https://www.worldlifeexpectancy.com/cause-of-death/all-cancers/by-country/'\n",
    "# t_cancer = pd.read_html(url)\n",
    " \n",
    "# Table 7 total health expenditure per capita (U.S. dollars, not inflation-adjusted)\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_total_health_expenditure_per_capita'\n",
    "t_healthexp = pd.read_html(url)\n",
    "t_healthexp[5].head()\n",
    "# keep first & forth column\n",
    "t_healthexp[5] = t_healthexp[5].iloc[ :, [0,3] ]\n",
    "\n",
    "# rename column names\n",
    "t_healthexp[5].columns = ['Country', 'Health Expenditure']\n",
    "t_healthexp[5].to_csv('t_healthexp.csv')\n",
    " \n",
    "# Table 8 heart disease rate, death rate per 100,000\n",
    "# url = 'https://www.worldlifeexpectancy.com/cause-of-death/coronary-heart-disease/by-country/'\n",
    "# t_heart = pd.read_html(url)\n",
    " \n",
    "# Table 9 List of countries by life expectancy\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy'\n",
    "t_life = pd.read_html(url)\n",
    "t_life[2].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "recorded-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep second & third column\n",
    "t_life[2] = t_life[2].iloc[ :, [1,2] ]\n",
    "\n",
    "# rename column names\n",
    "t_life[2].columns = ['Country', 'Life Expectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_life[2].to_csv('t_life.csv')\n",
    " \n",
    "# Table 10 stroke rate, death rate per 100,000\n",
    "# url = 'https://www.worldlifeexpectancy.com/cause-of-death/stroke/by-country/'\n",
    "# t_stroke = pd.read_html(url)\n",
    " \n",
    "df1 = pd.read_csv('t_birth.csv')\n",
    "df2 = pd.read_csv('t_cancer.csv')\n",
    "df3 = pd.read_csv('t_dengue.csv')\n",
    "df4 = pd.read_csv('t_env.csv')\n",
    "df5 = pd.read_csv('t_gdp.csv')\n",
    "df6 = pd.read_csv('t_healthexp.csv')\n",
    "df7 = pd.read_csv('t_heart.csv')\n",
    "df8 = pd.read_csv('t_pop.csv')\n",
    "df9 = pd.read_csv('t_stroke.csv')\n",
    "# convert country names to lower string, as merging reference ID\n",
    "t_life[2]['Country'] = t_life[2]['Country'].str.lower()\n",
    "df1['Country'] = df1['Country'].str.lower()\n",
    "df2['Country'] = df2['Country'].str.lower()\n",
    "df3['Country'] = df3['Country'].str.lower()\n",
    "df4['Country'] = df4['Country'].str.lower()\n",
    "df5['Country'] = df5['Country'].str.lower()\n",
    "df6['Country'] = df6['Country'].str.lower()\n",
    "df7['Country'] = df7['Country'].str.lower()\n",
    "df8['Country'] = df8['Country'].str.lower()\n",
    "df9['Country'] = df9['Country'].str.lower()\n",
    "df2.head()\n",
    "# merge data using country names as reference ID\n",
    "df = pd.merge(t_life[2], df1, on='Country', how='outer')\n",
    "df = pd.merge(df, df2, on='Country', how='outer')\n",
    "df = pd.merge(df, df3, on='Country', how='outer')\n",
    "df = pd.merge(df, df4, on='Country', how='outer')\n",
    "df = pd.merge(df, df5, on='Country', how='outer')\n",
    "df = pd.merge(df, df6, on='Country', how='outer')\n",
    "df = pd.merge(df, df7, on='Country', how='outer')\n",
    "df = pd.merge(df, df8, on='Country', how='outer')\n",
    "df = pd.merge(df, df9, on='Country', how='outer')\n",
    "df = df[ ['Country', 'Birth Rate', 'Cancer Rate', 'Dengue_Cases', 'EPI', 'GDP(US$mil)', 'Health Expenditure', 'Heart Disease Rate', 'Population', 'Area(km²)', 'Pop_density', 'Stroke Rate', 'Life Expectancy'] ]\n",
    "# save df (merged data, contains duplicates as some countries are named differently, eg. United Kingdom vs UK)\n",
    "df.to_csv('df.csv')\n",
    " \n",
    "# I have manually merged duplicate data with different names (in df.csv), and saved in df2.csv\n",
    "# read df2 (with distinct countries, with null fields)\n",
    "df = pd.read_csv('df2.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace null field in each column by median of column values\n",
    "df['Birth Rate'].fillna(df['Birth Rate'].median(), inplace=True)\n",
    "df['Cancer Rate'].fillna(df['Cancer Rate'].median(), inplace=True)\n",
    "df['Dengue Cases'].fillna(df['Dengue Cases'].median(), inplace=True)\n",
    "df['EPI'].fillna(df['EPI'].median(), inplace=True)\n",
    "df['GDP'].fillna(df['GDP'].median(), inplace=True)\n",
    "df['Health Expenditure'].fillna(df['Health Expenditure'].median(), inplace=True)\n",
    "df['Heart Disease Rate'].fillna(df['Heart Disease Rate'].median(), inplace=True)\n",
    "df['Population'].fillna(df['Population'].median(), inplace=True)\n",
    "df['Area'].fillna(df['Area'].median(), inplace=True)\n",
    "df['Pop Density'].fillna(df['Pop Density'].median(), inplace=True)\n",
    "df['Stroke Rate'].fillna(df['Stroke Rate'].median(), inplace=True)\n",
    "df['Life Expectancy'].fillna(df['Life Expectancy'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "# save df3 (full dataset with distinct countries, without null fields)\n",
    "df.to_csv('df3.csv', index = False)    # without index column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-peter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stretch-stock",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "df = pd.read_csv('df3.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice data into features X and target y\n",
    "X = df[ ['Birth Rate', 'Cancer Rate', 'Dengue Cases', 'EPI', 'GDP', 'Health Expenditure',\n",
    "         'Heart Disease Rate', 'Population', 'Area', 'Pop Density', 'Stroke Rate'] ].astype(float)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "y = df[ \"Life Expectancy\" ].astype(float)    # y is a series\n",
    "# y = df.loc[:,\"Life Expectancy\"].astype(float)   # alternate code, same outcome\n",
    "\n",
    "# Baseline results - model / fit / summarize, lots of bad Pvalue>0.05\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the correlations\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation with Seaborn\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "sns.heatmap(df.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all of the variable-to-variable relations as scatterplots\n",
    "# Note: there are outliers, and data points are concentrated on the left side (ie, right skewed)\n",
    "sns.pairplot(df, height=1.5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-length",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interim-injection",
   "metadata": {},
   "source": [
    "# 3. Feature Selection\n",
    "(i) Drop feature one by one\n",
    "Drop feature one by one to see its effect on R^2\n",
    "\n",
    "R^2 will be lower when a significant feature has been dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use \"Ctrl-/\" to include or remove each commenting\n",
    "X = df[ [\n",
    "#     'Birth Rate', \n",
    "    'Cancer Rate', \n",
    "    'Dengue Cases', \n",
    "    'EPI', \n",
    "    'GDP', \n",
    "    'Health Expenditure',\n",
    "    'Heart Disease Rate', \n",
    "    'Population', \n",
    "    'Area', \n",
    "    'Pop Density', \n",
    "    'Stroke Rate'\n",
    "                ] ].astype(float)\n",
    "X = sm.add_constant(X)\n",
    "y = df[ \"Life Expectancy\" ].astype(float)    # y is a series\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()\n",
    "\n",
    "# original, all features included, R^2 = 0.749\n",
    "# without Birth Rate, R^2 = 0.597 (=> significant feature)\n",
    "# without Cancer Rate, R^2 = 0.748\n",
    "# without Dengue Cases, R^2 = 0.748\n",
    "# without EPI, R^2 = 0.724 (=> significant feature)\n",
    "# without GDP, R^2 = 0.749\n",
    "# without Health Expenditure, R^2 =0.747\n",
    "# without Heart Disease Rate, R^2 = 0.748\n",
    "# without Population, R^2 = 0.748\n",
    "# without Area, R^2 = 0.749\n",
    "# without Pop Density, R^2 = 0.746\n",
    "# without Stroke Rate, R^2 = 0.711 (=> significant feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL ONLY ONCE, to replace each outlier value with the next highest value\n",
    "# Do it in 2 steps: first replace max-value by null, then replace null by the new max-value\n",
    "\n",
    "df['Dengue Cases'].replace(df['Dengue Cases'].max(), np.nan, inplace=True)   # Brazil\n",
    "df['Dengue Cases'].replace(np.nan, df['Dengue Cases'].max(), inplace=True)\n",
    "\n",
    "df['GDP'].replace(df['GDP'].max(), np.nan, inplace=True)   # USA\n",
    "df['GDP'].replace(df['GDP'].max(), np.nan, inplace=True)   # China\n",
    "df['GDP'].replace(np.nan, df['GDP'].max(), inplace=True)\n",
    "\n",
    "df['Population'].replace(df['Population'].max(), np.nan, inplace=True)   # China\n",
    "df['Population'].replace(df['Population'].max(), np.nan, inplace=True)   # India\n",
    "df['Population'].replace(np.nan, df['Population'].max(), inplace=True)\n",
    "\n",
    "df['Area'].replace(df['Area'].max(), np.nan, inplace=True)   # Russia\n",
    "df['Area'].replace(np.nan, df['Area'].max(), inplace=True)\n",
    "\n",
    "df['Pop Density'].replace(df['Pop Density'].max(), np.nan, inplace=True)   # Singapore\n",
    "df['Pop Density'].replace(np.nan, df['Pop Density'].max(), inplace=True)\n",
    "# check results after removing outliers (R^2 = 0.737)\n",
    "# Pop Density becomes significant feature (P-value becomes < 0.05)\n",
    "X, y = df.drop(columns=['Life Expectancy', 'Country'], axis=1), df['Life Expectancy']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise pair plot after removing outliers\n",
    "sns.pairplot(df, height=1.5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-visitor",
   "metadata": {},
   "source": [
    "# (iii) Apply LOG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LOG function to all 11 features\n",
    "df = pd.read_csv('df3.csv')\n",
    "\n",
    "df['Birth Rate']         = np.log( df['Birth Rate'] )\n",
    "df['Cancer Rate']        = np.log( df['Cancer Rate'] )\n",
    "df['Dengue Cases']       = np.log( df['Dengue Cases'] )\n",
    "df['EPI']                = np.log( df['EPI'] )\n",
    "df['GDP']                = np.log( df['GDP'] )     # becomes a significant feature\n",
    "df['Health Expenditure'] = np.log( df['Health Expenditure'] )\n",
    "df['Heart Disease Rate'] = np.log( df['Heart Disease Rate'] )     # becomes a significant feature\n",
    "df['Population']         = np.log( df['Population'] )     # becomes a significant feature\n",
    "df['Area']               = np.log( df['Area'] )     # becomes a significant feature\n",
    "df['Pop Density']        = np.log( df['Pop Density'] )\n",
    "df['Stroke Rate']        = np.log( df['Stroke Rate'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results after applying LOG (R^2 = 0.740)\n",
    "X, y = df.drop(columns=['Life Expectancy', 'Country'], axis=1), df['Life Expectancy']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-array",
   "metadata": {},
   "source": [
    "# Visualise pair plot for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair Plot with all 11 features\n",
    "# Note: outliers have been removed using the LOG function alone\n",
    "sns.pairplot(df, height=1.5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-outreach",
   "metadata": {},
   "source": [
    "# 4. Model Selection\n",
    "(a) Regression with Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary Least Squares Regression with Statsmodels, Option 1 (similar to R coding)\n",
    "\n",
    "df = pd.read_csv('df3.csv')\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.columns = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8','X9', 'X10', 'X11', 'Y']\n",
    "\n",
    "#1a Create your feature matrix (X) and target vector (y)\n",
    "y, X = patsy.dmatrices('Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11', data=df, return_type=\"dataframe\")\n",
    "\n",
    "#1b Create your model\n",
    "model = sm.OLS(y, X)\n",
    "#2 Fit your model to your training set\n",
    "result = model.fit()\n",
    "#3 Print summary statistics of the model's performance\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary Least Squares Regression with Statsmodels, Option 2 (python method), same results as Option 1\n",
    "\n",
    "df = pd.read_csv('df3.csv')\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.columns = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8','X9', 'X10', 'X11', 'Y']\n",
    "# df.head()\n",
    "\n",
    "#1 Define the model\n",
    "model = smf.ols('Y ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11', data=df)\n",
    "#2 Fit the model\n",
    "result = model.fit()\n",
    "#3 Print summary statistics of the model's performance\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-prospect",
   "metadata": {},
   "source": [
    "# (b) Regression using SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "# # Ordinary Least Squares Regression with sklearn\n",
    "\n",
    "df = pd.read_csv('df3.csv')\n",
    "df.drop('Country', axis=1, inplace=True)\n",
    "df.columns = ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8','X9', 'X10', 'X11', 'Y']\n",
    "# df.head()\n",
    "\n",
    "model = LinearRegression()\n",
    "X = df[ ['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8','X9', 'X10', 'X11'] ]\n",
    "y = df[ ['Y'] ]\n",
    "# Fit the model to the full dataset\n",
    "model.fit(X, y)\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "print(model.score(X, y))\n",
    "# print out intercept\n",
    "print(model.intercept_)\n",
    "# print out other coefficients\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out 20% of the data for validation, to find optimal alpha\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "# Mean Absolute Error (MAE) for validation\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use lassoCV to find the optimal ALPHA value for L1 regularization\n",
    "# Scale the data as before\n",
    "std = StandardScaler()\n",
    "std.fit(X_train.values)\n",
    "# Scale the Predictors on both the train and validation set\n",
    "X_train_scaled = std.transform(X_train.values)\n",
    "X_val_scaled = std.transform(X_val.values)\n",
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-3,3,200)   # alpha varies from 0.001 to 1000\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "# This is the best alpha value found\n",
    "lasso_model.alpha_ \n",
    "# 0.2582618760682675 without LOG function\n",
    "# 0.0032550885998350564 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all coefficients in the model with optimal alpha\n",
    "list(zip(X_train.columns, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the MAE\n",
    "mae(y_val, lasso_model.predict(X_val_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the R^2\n",
    "r2_score(y_val, lasso_model.predict(X_val_scaled))\n",
    "# 0.6778582657678913 without LOG function\n",
    "# 0.7013586553900932 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: lars_path takes numpy matrices, not pandas dataframes\n",
    "from sklearn.linear_model import lars_path\n",
    "print(\"Computing regularization path using the LARS ...\")\n",
    "alphas, _, coefs = lars_path(X_train_scaled, y_train.values, method='lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the LARS path\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.legend(X_train.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use RidgeCV to find the optimal ALPHA value for L2 regularization\n",
    "# Scale the data as before\n",
    "std = StandardScaler()\n",
    "std.fit(X_train.values)\n",
    "# Scale the Predictors on both the train and validation set\n",
    "X_train_scaled = std.transform(X_train.values)\n",
    "X_val_scaled = std.transform(X_val.values)\n",
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-3,3,200)   # alpha varies from 0.001 to 1000\n",
    "ridge_model = RidgeCV(alphas = alphavec, cv=5)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "# This is the best alpha value found\n",
    "ridge_model.alpha_\n",
    "# 25.23539170434766 without LOG function\n",
    "# 0.2097046401323233 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all coefficients in the model with optimal alpha\n",
    "list(zip(X_train.columns, ridge_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the MAE\n",
    "mae(y_val, ridge_model.predict(X_val_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(ridge_model.predict(X_val_scaled) - y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the R^2\n",
    "r2_score(y_val, ridge_model.predict(X_val_scaled))\n",
    "# 0.6815718599477412 without LOG function\n",
    "# 0.7001803890388709 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use ElasticNetCV to find the optimal ALPHA value\n",
    "# Scale the data as before\n",
    "std = StandardScaler()\n",
    "std.fit(X_train.values)\n",
    "# Scale the Predictors on both the train and validation set\n",
    "X_train_scaled = std.transform(X_train.values)\n",
    "X_val_scaled = std.transform(X_val.values)\n",
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-3,3,200)   # alpha varies from 0.001 to 1000\n",
    "elasticnet_model = ElasticNetCV(alphas = alphavec, cv=5)\n",
    "elasticnet_model.fit(X_train_scaled, y_train)\n",
    "# This is the best alpha value it found\n",
    "elasticnet_model.alpha_\n",
    "# 0.1956398343517063 without LOG function\n",
    "# 0.0016257556664437934 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all coefficients in the model with optimal alpha\n",
    "list(zip(X_train.columns, ridge_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the MAE\n",
    "mae(y_val, elasticnet_model.predict(X_val_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set using the new model, and find the R^2\n",
    "r2_score(y_val, elasticnet_model.predict(X_val_scaled))\n",
    "# 0.681292482381891 without LOG function\n",
    "# 0.7004421000497352 after applying LOG function to all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FINAL set of 8 features (Drop 3x features that are insignificant)\n",
    "## use LOG function on all 8 features, outliers have been removed using the LOG function alone)\n",
    "df = pd.read_csv('df3.csv')\n",
    "X = df[ ['Birth Rate', 'EPI', 'GDP', 'Heart Disease Rate', 'Population', 'Area', 'Pop Density', 'Stroke Rate'] ].astype(float)\n",
    "X = np.log(X)\n",
    "y = df[ \"Life Expectancy\" ].astype(float)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to check R^2 score for all models with best alpha, using manual split (see below for R^2 using CV, more robust)\n",
    "# hold out 20% of the data for validation \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.2, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the 5 models for training & validation:\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear regression val R^2: {lm.score(X_val, y_val):.3f}')\n",
    "\n",
    "#Feature scaling for train/val data so that we can run our ridge/lasso/elasticnet model on each\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_val_scaled = scaler.transform(X_val.values)\n",
    "\n",
    "lm_ridge = Ridge(alpha=0.2097046401323233)\n",
    "lm_ridge.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge regression val R^2: {lm_ridge.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_lasso = Lasso(alpha=0.0032550885998350564)\n",
    "lm_lasso.fit(X_train_scaled, y_train)\n",
    "print(f'Lasso regression val R^2: {lm_lasso.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "lm_elasticnet = ElasticNet(alpha=0.0016257556664437934)\n",
    "lm_elasticnet.fit(X_train_scaled, y_train)\n",
    "print(f'ElasticNet regression val R^2: {lm_elasticnet.score(X_val_scaled, y_val):.3f}')\n",
    "\n",
    "#Feature transforms for train/val data so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2) \n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_val_poly = poly.transform(X_val.values)\n",
    "\n",
    "lm_poly = LinearRegression()\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression val R^2: {lm_poly.score(X_val_poly, y_val):.3f}')\n",
    "\n",
    "# Linear regression val R^2: 0.713\n",
    "# Ridge regression val R^2: 0.712\n",
    "# Lasso regression val R^2: 0.713\n",
    "# ElasticNet regression val R^2: 0.712\n",
    "# Degree 2 polynomial regression val R^2: 0.663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation using KFold (on the 100% dataset, without manually splitting)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Feature transform/scaling so that we can run our ridge/lasso/elasticnet model \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.values)\n",
    "#Feature transform/scaling so that we can run our poly model \n",
    "poly = PolynomialFeatures(degree=2) \n",
    "X_poly = poly.fit_transform(X.values)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 1)\n",
    "\n",
    "cvs_lm = cross_val_score(lm, X, y, cv=kf, scoring='r2')\n",
    "print(cvs_lm)\n",
    "print('Linear regression cv R^2:', round(np.mean(cvs_lm),3), '+-', round(np.std(cvs_lm),3) )\n",
    "\n",
    "cvs_ridge = cross_val_score(lm_ridge, X_scaled, y, cv=kf, scoring='r2')\n",
    "print(cvs_ridge)\n",
    "print('Ridge regression cv R^2:', round(np.mean(cvs_ridge),3), '+-', round(np.std(cvs_ridge),3) )\n",
    "\n",
    "cvs_lasso = cross_val_score(lm_lasso, X_scaled, y, cv=kf, scoring='r2')\n",
    "print(cvs_lasso)\n",
    "print('Lasso regression cv R^2:', round(np.mean(cvs_lasso),3), '+-', round(np.std(cvs_lasso),3) )\n",
    "\n",
    "cvs_elasticnet = cross_val_score(lm_elasticnet, X_scaled, y, cv=kf, scoring='r2')\n",
    "print(cvs_elasticnet)\n",
    "print('ElasticNet regression cv R^2:', round(np.mean(cvs_elasticnet),3), '+-', round(np.std(cvs_elasticnet),3) )\n",
    "\n",
    "cvs_poly = cross_val_score(lm_poly, X_poly, y, cv=kf, scoring='r2')\n",
    "print(cvs_poly)\n",
    "print('Degree 2 polynomial Regression cv R^2:', round(np.mean(cvs_poly),3), '+-', round(np.std(cvs_poly),3) )\n",
    "\n",
    "# [0.63234622 0.72018406 0.59833499 0.77907137 0.78894173]\n",
    "# Linear regression cv R^2: 0.704 +- 0.077\n",
    "# [0.63054232 0.71808071 0.59325086 0.79001517 0.78518253]\n",
    "# Ridge regression cv R^2: 0.703 +- 0.08\n",
    "# [0.63160325 0.71952203 0.59659505 0.78254776 0.78747905]\n",
    "# Lasso regression cv R^2: 0.704 +- 0.078\n",
    "# [0.63118087 0.71887851 0.5950665  0.78651041 0.78648458]\n",
    "# ElasticNet regression cv R^2: 0.704 +- 0.079\n",
    "# [0.67260843 0.56723061 0.64473045 0.37774726 0.81111133]\n",
    "# Degree 2 polynomial Regression cv R^2: 0.615 +- 0.142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation on test dataset\n",
    "# note: insufficient data, so test all models on global dataset X, y\n",
    "X_test = X.copy()\n",
    "y_test = y.copy()\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Linear regression test R^2: {lm.score(X_test, y_test):.3f}')\n",
    "\n",
    "#Feature scaling for test data so that we can run our ridge/lasso/elasticnet model on each\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "X_test_scaled = scaler.transform(X_test.values)\n",
    "\n",
    "lm_ridge = Ridge(alpha=0.2097046401323233)\n",
    "lm_ridge.fit(X_train_scaled, y_train)\n",
    "print(f'Ridge regression test R^2: {lm_ridge.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "lm_lasso = Lasso(alpha=0.0032550885998350564)\n",
    "lm_lasso.fit(X_train_scaled, y_train)\n",
    "print(f'Lasso regression test R^2: {lm_lasso.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "lm_elasticnet = ElasticNet(alpha=0.0016257556664437934)\n",
    "lm_elasticnet.fit(X_train_scaled, y_train)\n",
    "print(f'ElasticNet regression test R^2: {lm_elasticnet.score(X_test_scaled, y_test):.3f}')\n",
    "\n",
    "#Feature transforms for test data so that we can run our poly model on each\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train.values)\n",
    "X_test_poly = poly.transform(X_test.values)\n",
    "\n",
    "lm_poly = LinearRegression()\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(f'Degree 2 polynomial regression test R^2: {lm_poly.score(X_test_poly, y_test):.3f}')\n",
    "\n",
    "\n",
    "cvs_lm = cross_val_score(lm, X_test, y_test, cv=kf, scoring='r2')\n",
    "print((\"Linear Regression test R^2:\"),( cvs_lm))\n",
    "print((\"Linear Regression test mean R^:\"), round(np.mean(cvs_lm),3), \"+-\", round(np.std(cvs_lm),3) )\n",
    "cvs_ridge = cross_val_score(lm_ridge, X_test_scaled, y_test, cv=kf, scoring='r2')\n",
    "print(('Ridge Regression test R^2:'), cvs_ridge)\n",
    "print( (\"Ridge Regression test mean R^:\"), round(np.mean(cvs_ridge),3), \"+-\", round(np.std(cvs_ridge),3) )\n",
    "cvs_lasso = cross_val_score(lm_lasso, X_test_scaled, y_test, cv=kf, scoring='r2')\n",
    "print(('Lasso Regression test R^2:'),cvs_lasso)\n",
    "print( (\"Lasso Regression test mean R^:\"), round(np.mean(cvs_lasso),3), \"+-\", round(np.std(cvs_lasso),3) )\n",
    "cvs_poly = cross_val_score(lm_poly, X_test_poly, y_test, cv=kf, scoring='r2')\n",
    "print(('Degree 2 polynomial regression test R^2:'),cvs_poly)\n",
    "print( ('Degree 2 polynomial regression test mean R^2:'), round(np.mean(cvs_poly),3), \"+-\", round(np.std(cvs_poly),3) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why Degree 2 polynomial regression test R^2: 0.802 ?\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(X_train_poly.shape)\n",
    "print(X_test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-tennis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "perfect-guess",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Linear Regression is the chosen model.\n",
    "\n",
    "Drop 3x features that are insignificant, and apply LOG function to ALL 8 features (LOG function can already take care of outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df3.csv')\n",
    "df.drop(columns=['Dengue Cases', 'Cancer Rate', 'Health Expenditure'], axis=1, inplace=True)\n",
    "df['Birth Rate']         = np.log( df['Birth Rate'] )\n",
    "df['EPI']                = np.log( df['EPI'] )\n",
    "df['GDP']                = np.log( df['GDP'] )\n",
    "df['Heart Disease Rate'] = np.log( df['Heart Disease Rate'] )\n",
    "df['Population']         = np.log( df['Population'] )\n",
    "df['Area']               = np.log( df['Area'] )\n",
    "df['Pop Density']        = np.log( df['Pop Density'] )\n",
    "df['Stroke Rate']        = np.log( df['Stroke Rate'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=['Life Expectancy', 'Country'], axis=1), df['Life Expectancy']\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-eligibility",
   "metadata": {},
   "source": [
    "# Model interpretation\n",
    "Unaffected by the features, your life expectancy is 62 years.\n",
    "\n",
    "If your country has low birth rate, add 6 more years to your life.\n",
    "\n",
    "If the EPI (Environment Performance Index) is high, add 8 more years to your life.\n",
    "\n",
    "If you live in a rich country, add half a year to your life.\n",
    "\n",
    "Finally for every unit (or rather LOG unit) decrease in stroke rate, 5 more years could be added to your life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing correlation with Seaborn, only FINAL 8 significant features\n",
    "# Note feature correlation < 0.7\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "sns.heatmap(df.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pair Plot with FINAL 8 significant features\n",
    "# Note: outliers have been removed using the LOG function alone\n",
    "sns.pairplot(df, height=1.5, aspect=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the residuals \n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(results.predict(), results.resid)\n",
    "plt.title(\"Residual plot\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Q-Q Plot\n",
    "import scipy.stats as stats\n",
    "\n",
    "# develop OLS with Sklearn\n",
    "lr = LinearRegression()\n",
    "fit = lr.fit(X,y) # for later use\n",
    "# Plot your predicted values on the x-axis, and your residuals on the y-axis\n",
    "df['predict'] = fit.predict(X)\n",
    "df['resid'] = y - df.predict\n",
    "# diagnose/inspect residual normality using qqplot:\n",
    "stats.probplot(df['resid'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.show()\n",
    "plt.savefig(\"diagnostics.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-pilot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-spokesman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-college",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-potter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-start",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-victorian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-sheffield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-christian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-orange",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-accuracy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-sound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-johnson",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
